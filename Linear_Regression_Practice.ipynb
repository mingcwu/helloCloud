{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s):  (Group Assignment - one person turns the notebook in, all members are required to review)\n",
    "\n",
    "# Date:\n",
    "\n",
    "# Class:  (Summer 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Linear Regression on the US Housing Price Data \"USA_Housing.csv\"\n",
    "## Knowledge Discovery in Databases - Data Mining\n",
    "## DIRECTIONS\n",
    "### Review all code and markdown.  Provide responses to questions at the end of the notebook (markdown, code)\n",
    "### Turn in this notebook via Canvas in the assignment area\n",
    "#### credits:  Github tirthajyoti/Machine-Learning-with-Python\n",
    "#### prepared w/edits for UNCC by Dr. Pamela Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1:  Review this primer on Linear Regression\n",
    "\n",
    "In statistics, linear regression is a popular approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the model is labeled multiple linear regression.\n",
    "\n",
    "In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models. Most commonly, the conditional mean of the response given the values of the explanatory variables (or predictors) is assumed to be an affine function of those values; less commonly, the conditional median or some other quantile is used. Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis. \n",
    "\n",
    "Linear regression models are often fitted using the least squares approach, but they may also be fitted in other ways (see note at end). Additionally, the least squares approach can be used to fit models that are not linear models. Although the terms \"least squares\" and \"linear model\" are closely linked, they are not synonymous.\n",
    "\n",
    "NOTE:  Other modelings for linear regression include minimizing the \"lack of fit\" in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares loss function as in ridge regression ($L_2$-norm penalty) and lasso ($L_1$-norm penalty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.  Import packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"USA_Housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.  Check basic information on the data set - our ulitmate goal will be to predict price based on the other numeric variables such as average area income, average area house age, etc.\n",
    "### Note price is a numeric variable (linear regression is suitable to predict price as a supervised method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info to get basic information\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe() to get the statistical summary of the various features of the data set\n",
    "df.describe(percentiles=[0.1,0.25,0.5,0.75,0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'columns' method to get the names of the columns (features)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some exploratory data analysis with basic plotting and visualization on the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairplots using seaborn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of price (the predicted quantity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'].plot.hist(bins=25,figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'].plot.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation matrix and heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(df.corr(),annot=True,linewidths=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and variable sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a list of data frame column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_column = list(df.columns) # Making a list out of column names\n",
    "len_feature = len(l_column) # Length of column vector list\n",
    "l_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put all the numerical features in X and Price in y, ignore Address which is string and of course will not be used for our model for linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[l_column[0:len_feature-2]]\n",
    "y = df[l_column[len_feature-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature set size:\",X.shape)\n",
    "print(\"Variable set size:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-train split\n",
    "#### Now we will split our data into a training and testing split - 70% training and 30% testing.  We will train the model on the training split then evaluate the model on the test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import train_test_split function from scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create X and y train and test splits in one command using a split ratio and a random seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the size and shape of train/test splits (it should be in the ratio as per test_size parameter above)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training feature set size:\",X_train.shape)\n",
    "print(\"Test feature set size:\",X_test.shape)\n",
    "print(\"Training variable set size:\",y_train.shape)\n",
    "print(\"Test variable set size:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fit and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import linear regression model estimator from scikit-learn and instantiate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression() # Creating a Linear Regression object 'lm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model on to the instantiated object itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train,y_train) # Fit the linear model on to the 'lm' object itself i.e. no need to set this to another variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the intercept and coefficients and put them in a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The intercept term of the linear model:\", lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The coefficients of the linear model:\", lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idict = {'Coefficients':lm.intercept_}\n",
    "#idf = pd.DataFrame(data=idict,index=['Intercept'])\n",
    "cdf = pd.DataFrame(data=lm.coef_, index=X_train.columns, columns=[\"Coefficients\"])\n",
    "#cdf=pd.concat([idf,cdf], axis=0)\n",
    "cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of standard errors and t-statistic for the coefficients\n",
    "### Important:  see list of features in the order of importance for predicting the house price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=X_train.shape[0]\n",
    "k=X_train.shape[1]\n",
    "dfN = n-k\n",
    "train_pred=lm.predict(X_train)\n",
    "train_error = np.square(train_pred - y_train)\n",
    "sum_error=np.sum(train_error)\n",
    "se=[0,0,0,0,0]\n",
    "for i in range(k):\n",
    "    r = (sum_error/dfN)\n",
    "    r = r/np.sum(np.square(X_train[list(X_train.columns)[i]]-X_train[list(X_train.columns)[i]].mean()))\n",
    "    se[i]=np.sqrt(r)\n",
    "cdf['Standard Error']=se\n",
    "cdf['t-statistic']=cdf['Coefficients']/cdf['Standard Error']\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Therefore, features arranged in the order of importance for predicting the house price\\n\",'-'*90,sep='')\n",
    "l=list(cdf.sort_values('t-statistic',ascending=False).index)\n",
    "print(' > \\n'.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=list(cdf.index)\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = gridspec.GridSpec(2,3)\n",
    "#f, ax = plt.subplots(nrows=1,ncols=len(l), sharey=True)\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.scatter(df[l[0]],df['Price'])\n",
    "ax0.set_title(l[0]+\" vs. Price\", fontdict={'fontsize':20})\n",
    "\n",
    "ax1 = plt.subplot(gs[1])\n",
    "ax1.scatter(df[l[1]],df['Price'])\n",
    "ax1.set_title(l[1]+\" vs. Price\",fontdict={'fontsize':20})\n",
    "\n",
    "ax2 = plt.subplot(gs[2])\n",
    "ax2.scatter(df[l[2]],df['Price'])\n",
    "ax2.set_title(l[2]+\" vs. Price\",fontdict={'fontsize':20})\n",
    "\n",
    "ax3 = plt.subplot(gs[3])\n",
    "ax3.scatter(df[l[3]],df['Price'])\n",
    "ax3.set_title(l[3]+\" vs. Price\",fontdict={'fontsize':20})\n",
    "\n",
    "ax4 = plt.subplot(gs[4])\n",
    "ax4.scatter(df[l[4]],df['Price'])\n",
    "ax4.set_title(l[4]+\" vs. Price\",fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-square of the model fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared value of this fit:\",round(metrics.r2_score(y_train,train_pred),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction, error estimate, and regression evaluation matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction using the lm model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)\n",
    "print (\"Type of the predicted object:\", type(predictions))\n",
    "print (\"Size of the predicted object:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter plot of predicted price and y_test set to see if the data fall on a 45 degree straight line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Actual vs. predicted house prices\",fontsize=25)\n",
    "plt.xlabel(\"Actual test set house prices\",fontsize=18, color=\"red\")\n",
    "plt.ylabel(\"Predicted house prices\", fontsize=18)\n",
    "plt.scatter(x=y_test,y=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting histogram of the residuals i.e. predicted errors (expect a normally distributed pattern)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Histogram of residuals to check for normality\",fontsize=25)\n",
    "plt.xlabel(\"Residuals\",fontsize=18)\n",
    "plt.ylabel(\"Kernel density\", fontsize=18)\n",
    "sns.distplot([y_test-predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter plot of residuals and predicted values (Homoscedasticity)**<p>Why do we care?</p><p><a href=\"https://www.statisticshowto.datasciencecentral.com/heteroscedasticity-simple-definition-examples/\">Heteroscedasticity and Homoscedasticity</a></p>\n",
    "### This is important!  Take the time to review the article!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Residuals vs. predicted values plot (Homoscedasticity)\\n\",fontsize=25)\n",
    "plt.xlabel(\"Predicted house prices\",fontsize=18)\n",
    "plt.ylabel(\"Residuals\", fontsize=18)\n",
    "plt.scatter(x=predictions,y=y_test-predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression evaluation metrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean absolute error (MAE):\", metrics.mean_absolute_error(y_test,predictions))\n",
    "print(\"Mean square error (MSE):\", metrics.mean_squared_error(y_test,predictions))\n",
    "print(\"Root mean square error (RMSE):\", np.sqrt(metrics.mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-square value** - the R-sqared value of predictions is .919\n",
    "<p>Evaluating R-squared - the coefficient of Determination</p><p><a href=\"https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/coefficient-of-determination-r-squared/\">R-squared</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared value of predictions:\",round(metrics.r2_score(y_test,predictions),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTIONS - ANSWER THE FOLLOWING QUESTIONS BY INSERTING MARKDOWN CELLS BELOW WITH THE QUESTION NUMBER AND THE ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  What type of variables are acceptable for linear regression for the X variable(s)?  The Y variable?<br>\n",
    "2.  What variable was discarded from the original dataset and why?\n",
    "3.  What is the purpose of the training and test data set?\n",
    "4.  When do you need to standardize the variables in regression analysis?\n",
    "5.  What is the purpose of plotting the variables to check for homoscedasticity?\n",
    "6.  This model produced a coefficient of determination of .919.  Is this good?  What does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
